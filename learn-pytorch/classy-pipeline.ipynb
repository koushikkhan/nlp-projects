{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a67cc70-3165-4455-af10-77ddf1679b61",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce5ccdb-340f-40d8-ba6a-7ad6afe7fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 13:55:38.168547: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 13:55:38.171748: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 13:55:38.218714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 13:55:39.057489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83d697-1405-4e65-a690-cdc51cc0818b",
   "metadata": {},
   "source": [
    "# The StepByStep Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7278cf-11ce-409a-af11-f5ce9eee2e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep():\n",
    "    def __init__(self, model, loss_func, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes\n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "        \n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "        \n",
    "        # Creates the train_step function for our model,\n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step_fn = self._make_train_step_fn()\n",
    "        \n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step_fn = self._make_val_step_fn()\n",
    "        \n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = ('cuda' if torch.cuda.is_available()\n",
    "            else 'cpu')\n",
    "            print(f\"Couldn't send it to {device}, \\\n",
    "            sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "            \n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader\n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        \n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to\n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "        \n",
    "    def _make_train_step_fn(self):\n",
    "        # This method does not need ARGS... it can use directly\n",
    "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "        \n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # set the model to TRAIN mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Step 1: computes model's predicted output - forward pass\n",
    "            y_hat = self.model(x)\n",
    "            \n",
    "            # Step 2: computes the loss\n",
    "            loss = self.loss_fn(y_hat, y)\n",
    "            \n",
    "            # Step 3: computes gradients w.r.t model params\n",
    "            loss.backward()\n",
    "            \n",
    "            # Step 4: Updates params using gradients and the learning rate\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # returns the loss\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # set the model to EVAL mode\n",
    "            self.model.eval()\n",
    "            \n",
    "            # Step 1: computes model's predicted output - forward pass\n",
    "            y_hat = self.model(x)\n",
    "            \n",
    "            # Step 2: computes the loss\n",
    "            loss = self.loss_fn(y_hat, y)\n",
    "                        \n",
    "            # returns the loss\n",
    "            return loss.item()\n",
    "        \n",
    "        # Returns the function that will be called inside the validation loop\n",
    "        return perform_val_step_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "pyenv-bol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
