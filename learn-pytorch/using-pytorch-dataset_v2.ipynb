{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a87ee6-6655-4c9e-8b40-f03c723b0166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 13:34:21.080352: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 13:34:21.083681: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-31 13:34:21.131349: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 13:34:22.010603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter # pip install --force-reinstall charset-normalizer==3.1.0\n",
    "from torch import optim\n",
    "from data_utils import *\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f6aac7-91d7-4c6c-8ddf-3d74ad6f531b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu count: 0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device)\n",
    "\n",
    "n_cudas = torch.cuda.device_count()\n",
    "print(f\"gpu count: {n_cudas}\")\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da30472-b8f3-48d1-93fa-c05689d823fd",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5005e752-e050-457c-a604-5696aa7b7ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create raw dataset\n",
    "x, y = GenerateRandomDataset.generate_slr_dataset_v2(\n",
    "    true_bias=3.0, \n",
    "    true_weight=4.0, \n",
    "    sample_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76fc6c79-455a-48b6-b2dc-ed8aeec2e669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# into Pytorch's tensor\n",
    "x_tensor = torch.as_tensor(x).float().to(device)\n",
    "y_tensor = torch.as_tensor(y).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc276c6-f549-4a2d-a300-a8837b9e4ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# builds datasets\n",
    "dataset = CustomDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922c0d60-4a2a-49fa-9786-56c1523c4c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs the split\n",
    "ratio = .8\n",
    "n_total = len(dataset)\n",
    "n_train = int(n_total * ratio)\n",
    "n_val = n_total - n_train\n",
    "train_data, val_data = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd484b3-4071-4114-86d1-e596fd791491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# builds dataloaders\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8078aeb9-7282-4e5b-aa8e-2b5e5a06dc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve mini-batches\n",
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca57bc-453b-4636-a81a-4849c4db0312",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad315f7-5c47-4f73-a76d-27f9bcff1e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "class MyLinearRegressionNested(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=1, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_hat = self.linear(x)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9609ca69-b842-4e5d-a68a-49c3e3558962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create model instance\n",
    "reg_model = MyLinearRegressionNested().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edbe36-59dc-4dfb-a212-c1459b2bf7b6",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871bbbb9-1f65-481b-be93-6e32ae361cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d94c38d0-3b51-4d6e-9e9e-87a660d5d744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 0.1\n",
    "optimizer = optim.SGD(params=reg_model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "perform_train_step = make_train_step_fn(model=reg_model, loss_func=loss_fn, optimizer=optimizer)\n",
    "perform_val_step = make_val_step_fn(model=reg_model, loss_func=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91da95ab-16fa-46bd-849f-d3524a903a27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 1.21706, Validation Loss: 0.03525\n",
      "Epoch: 1, Training Loss: 0.02363, Validation Loss: 0.01420\n",
      "Epoch: 2, Training Loss: 0.01366, Validation Loss: 0.01228\n",
      "Epoch: 3, Training Loss: 0.01116, Validation Loss: 0.01084\n",
      "Epoch: 4, Training Loss: 0.01057, Validation Loss: 0.01083\n",
      "Epoch: 5, Training Loss: 0.01031, Validation Loss: 0.01063\n",
      "Epoch: 6, Training Loss: 0.01031, Validation Loss: 0.01018\n",
      "Epoch: 7, Training Loss: 0.01029, Validation Loss: 0.00986\n",
      "Epoch: 8, Training Loss: 0.01026, Validation Loss: 0.00996\n",
      "Epoch: 9, Training Loss: 0.01051, Validation Loss: 0.01124\n",
      "Epoch: 10, Training Loss: 0.01024, Validation Loss: 0.01043\n",
      "Epoch: 11, Training Loss: 0.01019, Validation Loss: 0.01075\n",
      "Epoch: 12, Training Loss: 0.01025, Validation Loss: 0.01104\n",
      "Epoch: 13, Training Loss: 0.01016, Validation Loss: 0.01104\n",
      "Epoch: 14, Training Loss: 0.01024, Validation Loss: 0.01038\n",
      "Epoch: 15, Training Loss: 0.01029, Validation Loss: 0.00985\n",
      "Epoch: 16, Training Loss: 0.01030, Validation Loss: 0.01018\n",
      "Epoch: 17, Training Loss: 0.01018, Validation Loss: 0.01008\n",
      "Epoch: 18, Training Loss: 0.01023, Validation Loss: 0.01077\n",
      "Epoch: 19, Training Loss: 0.01018, Validation Loss: 0.01064\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "for i in range(num_epochs):\n",
    "    # train\n",
    "    loss = mini_batch(device=device, data_loader=train_loader, step_fn=perform_train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device=device, data_loader=val_loader, step_fn=perform_val_step)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Epoch: {i}, Training Loss: {loss:0.5f}, Validation Loss: {val_loss:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f850dc44-bcea-4de5-bdc6-15da8776862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'linear.weight': tensor([[3.9936]]), 'linear.bias': tensor([2.9960])})\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(reg_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53fc41-e298-4240-8403-73f574a5800f",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36fe8163-5ffe-4208-8de0-0f064c0acd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': reg_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': losses,\n",
    "    'val_loss': val_losses\n",
    "}\n",
    "\n",
    "# save checkpoint\n",
    "torch.save(checkpoint, 'reg_model_checkpoint_31052024.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1ef9a-4be4-4a61-b892-b0cf4e721ade",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbbc0abd-be8e-4ccb-ad84-287652a19e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model instance \n",
    "# as if there is no model in memory\n",
    "\n",
    "new_model = MyLinearRegressionNested().to(device)\n",
    "new_optimizer = optim.SGD(params=new_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab41a9f7-0568-42b0-8656-e36b8f673a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[-0.8549]])),\n",
       "             ('linear.bias', tensor([-0.2070]))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c6cb69-b1c0-4369-871d-0dffc024860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model components\n",
    "checkpoint_to_load = torch.load('reg_model_checkpoint_31052024.pth')\n",
    "\n",
    "new_model.load_state_dict(checkpoint_to_load['model_state_dict'])\n",
    "new_optimizer.load_state_dict(checkpoint_to_load['optimizer_state_dict'])\n",
    "\n",
    "saved_epoch = checkpoint['epoch']\n",
    "saved_losses = checkpoint['loss']\n",
    "saved_val_losses = checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "927997e9-65cd-4e2e-956b-3acf9229abf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLinearRegressionNested(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab5cea30-5e2d-4e5b-a85d-d3a05f21cdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'linear.weight': tensor([[3.9936]]), 'linear.bias': tensor([2.9960])})\n"
     ]
    }
   ],
   "source": [
    "print(new_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5797770-68dc-484f-981b-a65ec7a1505d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52722b4e-1591-497f-913d-706740778494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.7947],\n",
       "        [4.3538],\n",
       "        [5.2723]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs = torch.tensor([[0.20], [0.34], [0.57]])\n",
    "\n",
    "# set the model to eval mode\n",
    "new_model.eval()\n",
    "\n",
    "# compute predictions\n",
    "new_model(new_inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661ca2c-1e47-4be9-a430-06534e416a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "pyenv-bol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
